"""streamlit_rag_ui_hybrid.py â€“ Hybrid Modern RAG System with Text-to-SQL
=======================================================
ãƒãƒ£ãƒƒãƒˆç”»é¢ã¯ChatGPTé¢¨ã€ãã®ä»–ã¯æ´—ç·´ã•ã‚ŒãŸãƒ¢ãƒ€ãƒ³ãƒ‡ã‚¶ã‚¤ãƒ³
ç”¨èªè¾æ›¸ã‚¿ãƒ–ã‚’è¿½åŠ  (Added Term Dictionary Tab)

èµ·å‹•: streamlit run streamlit_rag_ui_hybrid.py
(Launch: streamlit run streamlit_rag_ui_hybrid.py)
"""
from __future__ import annotations

import streamlit as st

# â”€â”€ Page Configuration (æœ€å„ªå…ˆã§å‘¼ã³å‡ºã—) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="RAG System â€¢ Document Intelligence",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ãã®ä»–ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆset_page_configã®å¾Œï¼‰
import os
import json
import tempfile
import time
from pathlib import Path
from typing import Optional, List, Dict, Any
from datetime import datetime, timedelta
import uuid

from dotenv import load_dotenv
from sqlalchemy import create_engine, text
import pandas as pd
import numpy as np

from langchain_core.runnables import RunnableConfig

try:
    import plotly.graph_objects as go
    import plotly.express as px
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

# â”€â”€ Environment & Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
ENV_DEFAULTS = {
    # Azure OpenAI Settings
    "AZURE_OPENAI_API_KEY": os.getenv("AZURE_OPENAI_API_KEY", ""),
    "AZURE_OPENAI_ENDPOINT": os.getenv("AZURE_OPENAI_ENDPOINT", ""),
    "AZURE_OPENAI_API_VERSION": os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-01"),
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME": os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT_NAME", ""),
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME": os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME", ""),
    # Model names
    "EMBEDDING_MODEL_IDENTIFIER": os.getenv("EMBEDDING_MODEL_IDENTIFIER", "text-embedding-ada-002"),
    "LLM_MODEL_IDENTIFIER": os.getenv("LLM_MODEL_IDENTIFIER", "gpt-4o"),
    "COLLECTION_NAME": os.getenv("COLLECTION_NAME", "documents"),
    "FINAL_K": int(os.getenv("FINAL_K", 5)),
}

# PostgreSQL URL for term dictionary
PG_URL = os.getenv("PG_URL", "")

# â”€â”€ RAG System Import â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    from rag_system_enhanced import Config, RAGSystem
except ModuleNotFoundError:
    st.error("âŒ rag_system_enhanced.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•ã§ãã¾ã›ã‚“ã€‚")
    st.stop()
except ImportError as e:
    st.error(f"âŒ RAGã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    st.stop()

# â”€â”€ Hybrid CSS Design â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
    :root {
        /* ãƒ€ãƒ¼ã‚¯ãƒ†ãƒ¼ãƒã‚«ãƒ©ãƒ¼ (Dark theme colors) */
        --bg-primary: #0a0a0a; --bg-secondary: #141414; --bg-tertiary: #1a1a1a;
        --surface: #242424; --surface-hover: #2a2a2a; --border: #333333;
        /* ChatGPTé¢¨ã‚«ãƒ©ãƒ¼ï¼ˆãƒãƒ£ãƒƒãƒˆéƒ¨åˆ†ç”¨ï¼‰ (ChatGPT-style colors (for chat part)) */
        --chat-bg: #343541; --sidebar-bg: #202123; --user-msg-bg: #343541;
        --ai-msg-bg: #444654; --chat-border: #4e4f60;
        /* ãƒ†ã‚­ã‚¹ãƒˆã‚«ãƒ©ãƒ¼ (Text colors) */
        --text-primary: #ffffff; --text-secondary: #b3b3b3; --text-tertiary: #808080;
        /* ã‚¢ã‚¯ã‚»ãƒ³ãƒˆã‚«ãƒ©ãƒ¼ (Accent colors) */
        --accent: #7c3aed; --accent-hover: #8b5cf6; --accent-light: rgba(124, 58, 237, 0.15);
        --accent-green: #10a37f;
        /* ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚«ãƒ©ãƒ¼ (Status colors) */
        --success: #10b981; --error: #ef4444; --warning: #f59e0b; --info: #3b82f6;
    }
    * { font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif; }
    .stApp { background: var(--bg-primary); color: var(--text-primary); }
    #MainMenu {visibility: hidden;} footer {visibility: hidden;} header {visibility: hidden;}
    ::-webkit-scrollbar { width: 8px; height: 8px; }
    ::-webkit-scrollbar-track { background: var(--bg-secondary); }
    ::-webkit-scrollbar-thumb { background: #555; border-radius: 4px; }
    ::-webkit-scrollbar-thumb:hover { background: #666; }

    /* ãƒ˜ãƒƒãƒ€ãƒ¼ã®ä¿®æ­£ (Header correction) */
    .main-header {
        background: linear-gradient(135deg, var(--accent) 0%, #a855f7 100%);
        padding: 0.1rem 1rem;
        border-radius: 16px;
        margin-bottom: 2rem;
        box-shadow: 0 8px 32px rgba(124, 58, 237, 0.3);
        max-width: 100%;
        margin-left: auto;
        margin-right: auto;
    }
    .header-title { font-size: 2.5rem; font-weight: 700; margin: 0; letter-spacing: -1px; }
    .header-subtitle { font-size: 1.1rem; opacity: 0.9; margin-top: 0.5rem; }
    .card { background: var(--surface); border: 1px solid var(--border); border-radius: 12px; padding: 1.5rem; margin-bottom: 1rem; }
    .chat-welcome { display: flex; flex-direction: column; align-items: center; justify-content: center; height: 300px; text-align: center; margin-top: -50px; }
    .chat-welcome h2 { color: var(--text-primary); font-size: 2rem; margin-bottom: 1rem; }
    .initial-input-container { margin-top: -100px; width: 100%; max-width: 700px; margin-left: auto; margin-right: auto; }
    .messages-area { padding: 20px 0; min-height: 400px; max-height: calc(100vh - 400px); overflow-y: auto; }
    .message-row { display: flex; padding: 16px 20px; gap: 16px; margin-bottom: 8px; } .user-message-row { background-color: var(--user-msg-bg); } .ai-message-row { background-color: var(--ai-msg-bg); }
    .avatar { width: 36px; height: 36px; border-radius: 4px; display: flex; align-items: center; justify-content: center; font-size: 14px; font-weight: 600; flex-shrink: 0; }
    .user-avatar { background-color: #5436DA; color: white; } .ai-avatar { background-color: var(--accent-green); color: white; }
    .message-content { color: var(--text-primary); line-height: 1.6; flex: 1; } .message-content p { margin: 0; }
    .chat-input-area { border-top: 1px solid var(--chat-border); padding: 20px; background-color: var(--chat-bg); border-radius: 0 0 12px 12px; }
    .source-container { background: var(--bg-secondary); border-radius: 12px; padding: 1.5rem; border: 1px solid var(--border); margin-top: 1rem; }
    .source-item { background: var(--surface); border-radius: 8px; padding: 1rem; margin-bottom: 0.75rem; border-left: 3px solid var(--accent); cursor: pointer; transition: all 0.2s ease; }
    .source-item:hover { transform: translateX(4px); background: var(--surface-hover); } .source-title { font-weight: 600; color: var(--text-primary); margin-bottom: 0.5rem; }
    .source-excerpt { font-size: 0.875rem; color: var(--text-secondary); line-height: 1.5; }
    .full-text-container { background: var(--surface); border: 1px solid var(--border); border-radius: 8px; padding: 1rem; max-height: 300px; overflow-y: auto; margin-top: 0.5rem; font-size: 0.875rem; line-height: 1.6; color: var(--text-primary); }
    .stat-card { background: var(--surface); border: 1px solid var(--border); border-radius: 12px; padding: 1.5rem; text-align: center; transition: transform 0.2s ease; } .stat-card:hover { transform: translateY(-2px); }
    .stat-number { font-size: 2rem; font-weight: 700; color: var(--accent); } .stat-label { color: var(--text-secondary); font-size: 0.875rem; text-transform: uppercase; letter-spacing: 0.5px; margin-top: 0.5rem; }
    .stButton > button { background: var(--accent); color: white; border: none; border-radius: 8px; padding: 0.75rem 1.5rem; font-weight: 500; transition: all 0.2s ease; } .stButton > button:hover { background: var(--accent-hover); transform: translateY(-1px); }
    .stTextInput > div > div > input, .stTextArea > div > div > textarea { background: var(--surface); border: 1px solid var(--border); color: var(--text-primary); border-radius: 8px; }
    .stTextInput > div > div > input:focus, .stTextArea > div > div > textarea:focus { border-color: var(--accent); box-shadow: 0 0 0 2px var(--accent-light); }
    .stFormLabel { color: var(--text-primary) !important; font-weight: 500; }
    .stTextInput input::placeholder, .stTextArea textarea::placeholder { color: var(--text-secondary) !important; }
    .stTextInput input, .stTextArea textarea, .stSelectbox > div > div > div[data-baseweb="select"] > div { color: var(--text-primary) !important; font-size: 1rem !important; }
    .stSelectbox > div > div > div { background: var(--surface); border: 1px solid var(--border); color: var(--text-primary); }
    .stTabs [data-baseweb="tab-list"] { background: transparent; gap: 0.5rem; }
    .stTabs [data-baseweb="tab"] { background: var(--surface); color: var(--text-secondary); border: 1px solid var(--border); border-radius: 8px; padding: 0.75rem 1.5rem; font-weight: 500; }
    .stTabs [aria-selected="true"] { background: var(--accent); color: white; border-color: var(--accent); }
    .stFileUploader > div { background: var(--surface); border: 2px dashed var(--border); border-radius: 12px; } .stFileUploader > div:hover { border-color: var(--accent); background: var(--surface-hover); }
    .stProgress > div > div > div > div { background: var(--accent); } div[data-testid="metric-container"] { background: var(--surface); border: 1px solid var(--border); border-radius: 8px; padding: 1rem; }
    .css-1d391kg { background: var(--bg-secondary); } .stAlert { background: var(--surface); color: var(--text-primary); border: 1px solid var(--border); }
    
    /* ç”¨èªè¾æ›¸ãƒ†ãƒ¼ãƒ–ãƒ«ç”¨ã®ã‚¹ã‚¿ã‚¤ãƒ« */
    .term-card {
        background: var(--surface);
        border: 1px solid var(--border);
        border-radius: 8px;
        padding: 1.2rem;
        margin-bottom: 0.8rem;
        transition: all 0.2s ease;
    }
    .term-card:hover {
        transform: translateX(2px);
        border-left: 3px solid var(--accent);
    }
    .term-headword {
        font-size: 1.1rem;
        font-weight: 600;
        color: var(--accent);
        margin-bottom: 0.5rem;
    }
    .term-definition {
        color: var(--text-primary);
        line-height: 1.5;
        margin-bottom: 0.5rem;
    }
    .term-synonyms {
        color: var(--text-secondary);
        font-size: 0.875rem;
    }
    .term-sources {
        color: var(--text-tertiary);
        font-size: 0.8rem;
        margin-top: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)

# â”€â”€ Helper Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _persist_uploaded_file(uploaded_file) -> Path:
    if uploaded_file is None:
        raise ValueError("Uploaded file cannot be None")
    tmp_dir = Path(tempfile.gettempdir()) / "rag_uploads"
    tmp_dir.mkdir(exist_ok=True)
    tmp_path = tmp_dir / uploaded_file.name
    with open(tmp_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return tmp_path

@st.cache_resource(show_spinner=False)
def initialize_rag_system(config_obj: Config) -> RAGSystem:
    return RAGSystem(config_obj)

def get_collection_statistics(rag: RAGSystem) -> Dict[str, Any]:
    if not rag:
        return {"documents": 0, "chunks": 0, "collection_name": "N/A"}
    try:
        engine = create_engine(rag.connection_string)
        with engine.connect() as conn:
            query = text("SELECT COUNT(DISTINCT document_id) AS num_documents, COUNT(*) AS num_chunks FROM document_chunks WHERE collection_name = :collection")
            result = conn.execute(query, {"collection": rag.config.collection_name}).first()
        return {
            "documents": result.num_documents if result else 0,
            "chunks": result.num_chunks if result else 0,
            "collection_name": rag.config.collection_name
        }
    except Exception as e:
        st.error(f"çµ±è¨ˆæƒ…å ±ã®å–å¾—ã«å¤±æ•—: {e}")
        return {"documents": 0, "chunks": 0, "collection_name": rag.config.collection_name if rag else "N/A"}

def get_documents_dataframe(rag: RAGSystem) -> pd.DataFrame:
    if not rag:
        return pd.DataFrame()
    try:
        engine = create_engine(rag.connection_string)
        with engine.connect() as conn:
            query = text("SELECT document_id, COUNT(*) as chunk_count, MAX(created_at) as last_updated FROM document_chunks WHERE collection_name = :collection GROUP BY document_id ORDER BY last_updated DESC")
            result = conn.execute(query, {"collection": rag.config.collection_name})
            df = pd.DataFrame(result.fetchall(), columns=["Document ID", "Chunks", "Last Updated"])
        if not df.empty and "Last Updated" in df.columns:
            df["Last Updated"] = pd.to_datetime(df["Last Updated"]).dt.strftime("%Y-%m-%d %H:%M")
        return df
    except Exception as e:
        st.error(f"ç™»éŒ²æ¸ˆã¿ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒªã‚¹ãƒˆã®å–å¾—ã«å¤±æ•—: {e}")
        return pd.DataFrame()

def get_query_history_data(days: int = 30) -> pd.DataFrame:
    dates = pd.date_range(end=datetime.now(), periods=days, freq='D')
    queries = [20 + int(10 * abs(np.sin(i / 5.0))) + np.random.randint(-3, 4) for i in range(days)]
    queries = [max(0, q) for q in queries]
    return pd.DataFrame({'Date': dates, 'Queries': queries})

def render_simple_chart(df: pd.DataFrame):
    """ç°¡å˜ãªãƒãƒ£ãƒ¼ãƒˆæç”»"""
    try:
        if df.empty:
            st.info("ãƒãƒ£ãƒ¼ãƒˆã‚’æç”»ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

        if not PLOTLY_AVAILABLE:
            st.warning("Plotlyãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚`pip install plotly plotly-express`ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
            return

        numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
        if not numeric_cols:
            st.info("æ•°å€¤å‹ã®åˆ—ãŒãªã„ãŸã‚ã€ãƒãƒ£ãƒ¼ãƒˆã‚’æç”»ã§ãã¾ã›ã‚“ã€‚")
            return

        categorical_cols = df.select_dtypes(include=['object', 'category', 'datetime64']).columns.tolist()

        chart_type_options = ["ãªã—"]
        if len(df.columns) >= 2 and categorical_cols and numeric_cols:
            chart_type_options.append("æ£’ã‚°ãƒ©ãƒ•")
        if numeric_cols:
            chart_type_options.append("æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•")
        if len(numeric_cols) >= 2:
            chart_type_options.append("æ•£å¸ƒå›³")

        if len(chart_type_options) == 1:
            st.info("é©åˆ‡ãªãƒ‡ãƒ¼ã‚¿å½¢å¼ã§ã¯ãªã„ãŸã‚ã€ãƒãƒ£ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã‚’é¸æŠã§ãã¾ã›ã‚“ã€‚")
            return

        chart_type = st.selectbox("å¯è¦–åŒ–ã‚¿ã‚¤ãƒ—ã‚’é¸æŠ:", chart_type_options, key=f"sql_chart_type_selector_{df.shape[0]}_{df.shape[1]}")

        if chart_type == "æ£’ã‚°ãƒ©ãƒ•":
            if categorical_cols and numeric_cols:
                x_col_bar = st.selectbox("Xè»¸ (ã‚«ãƒ†ã‚´ãƒª/æ—¥ä»˜)", categorical_cols, key=f"bar_x_sql_{df.shape[0]}")
                y_col_bar = st.selectbox("Yè»¸ (æ•°å€¤)", numeric_cols, key=f"bar_y_sql_{df.shape[0]}")
                if x_col_bar and y_col_bar:
                    fig = px.bar(df.head(25), x=x_col_bar, y=y_col_bar, title=f"{y_col_bar} by {x_col_bar}")
                    st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("æ£’ã‚°ãƒ©ãƒ•ã«ã¯ã‚«ãƒ†ã‚´ãƒªåˆ—ã¨æ•°å€¤åˆ—ãŒå¿…è¦ã§ã™ã€‚")

        elif chart_type == "æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•":
            y_cols_line = st.multiselect("Yè»¸ (æ•°å€¤ - è¤‡æ•°é¸æŠå¯)", numeric_cols, default=numeric_cols[0] if numeric_cols else None, key=f"line_y_sql_{df.shape[0]}")
            date_cols = df.select_dtypes(include=['datetime64']).columns.tolist()
            x_col_line_options = ["(ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹)"] + categorical_cols
            
            chosen_x_col = None
            if date_cols:
                x_col_line_options = ["(ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹)"] + date_cols + [c for c in categorical_cols if c not in date_cols]
                chosen_x_col = date_cols[0]
            elif categorical_cols:
                chosen_x_col = categorical_cols[0]

            x_col_line = st.selectbox("Xè»¸", x_col_line_options, index=x_col_line_options.index(chosen_x_col) if chosen_x_col and chosen_x_col in x_col_line_options else 0, key=f"line_x_sql_{df.shape[0]}")

            if y_cols_line:
                title_ys = ", ".join(y_cols_line)
                if x_col_line and x_col_line != "(ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹)":
                    fig = px.line(df.head(100), x=x_col_line, y=y_cols_line, title=f"{title_ys} over {x_col_line}", markers=True)
                else:
                    fig = px.line(df.head(100), y=y_cols_line, title=f"{title_ys} Trend", markers=True)
                st.plotly_chart(fig, use_container_width=True)
            
        elif chart_type == "æ•£å¸ƒå›³":
            if len(numeric_cols) >= 2:
                x_col_scatter = st.selectbox("Xè»¸ (æ•°å€¤)", numeric_cols, key=f"scatter_x_sql_{df.shape[0]}")
                y_col_scatter = st.selectbox("Yè»¸ (æ•°å€¤)", [nc for nc in numeric_cols if nc != x_col_scatter], key=f"scatter_y_sql_{df.shape[0]}")
                color_col_scatter_options = ["ãªã—"] + categorical_cols + [nc for nc in numeric_cols if nc != x_col_scatter and nc != y_col_scatter]
                color_col_scatter = st.selectbox("è‰²åˆ†ã‘ (ä»»æ„)", color_col_scatter_options, key=f"scatter_color_sql_{df.shape[0]}")

                if x_col_scatter and y_col_scatter:
                    fig = px.scatter(
                        df.head(500),
                        x=x_col_scatter, 
                        y=y_col_scatter, 
                        color=color_col_scatter if color_col_scatter != "ãªã—" else None,
                        title=f"{y_col_scatter} vs {x_col_scatter}" + (f" by {color_col_scatter}" if color_col_scatter != "ãªã—" else "")
                    )
                    st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("æ•£å¸ƒå›³ã«ã¯å°‘ãªãã¨ã‚‚2ã¤ã®æ•°å€¤åˆ—ãŒå¿…è¦ã§ã™ã€‚")

    except Exception as e:
        st.error(f"ãƒãƒ£ãƒ¼ãƒˆæç”»ã‚¨ãƒ©ãƒ¼: {type(e).__name__} - {e}")

def render_sql_result_in_chat(sql_details_dict: Dict[str, Any]):
    """ãƒãƒ£ãƒƒãƒˆå†…ã§ã®SQLé–¢é€£æƒ…å ±è¡¨ç¤º"""
    if not sql_details_dict or not isinstance(sql_details_dict, dict):
        st.warning("ãƒãƒ£ãƒƒãƒˆè¡¨ç¤ºç”¨ã®SQLè©³ç´°æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    with st.expander("ğŸ” å®Ÿè¡Œã•ã‚ŒãŸSQL (ãƒãƒ£ãƒƒãƒˆå†…)", expanded=False):
        st.code(sql_details_dict.get("generated_sql", "SQLãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"), language="sql")

    results_data_preview = sql_details_dict.get("results_preview")
    if results_data_preview and isinstance(results_data_preview, list) and len(results_data_preview) > 0:
        with st.expander("ğŸ“Š SQLå®Ÿè¡Œçµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (ãƒãƒ£ãƒƒãƒˆå†…)", expanded=False):
            try:
                df_chat_preview = pd.DataFrame(results_data_preview)
                st.dataframe(df_chat_preview, use_container_width=True, height = min(300, (len(df_chat_preview) + 1) * 35 + 3))
                
                total_fetched = sql_details_dict.get("row_count_fetched", 0)
                preview_count = len(results_data_preview)
                if total_fetched > preview_count:
                    st.caption(f"çµæœã®æœ€åˆã®{preview_count}ä»¶ã‚’è¡¨ç¤ºï¼ˆå…¨{total_fetched}ä»¶å–å¾—ï¼‰ã€‚")
                elif total_fetched > 0:
                    st.caption(f"å…¨{total_fetched}ä»¶ã®çµæœã‚’è¡¨ç¤ºã€‚")
            except Exception as e:
                st.error(f"ãƒãƒ£ãƒƒãƒˆå†…ã§ã®SQLçµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
    elif sql_details_dict.get("success"):
        with st.expander("ğŸ“Š SQLå®Ÿè¡Œçµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (ãƒãƒ£ãƒƒãƒˆå†…)", expanded=False):
            st.info("SQLã‚¯ã‚¨ãƒªã¯æˆåŠŸã—ã¾ã—ãŸãŒã€è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# â”€â”€ ç”¨èªè¾æ›¸é–¢é€£ã®é–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(ttl=60, show_spinner=False)
def load_terms_from_db(keyword: str = "") -> pd.DataFrame:
    """PostgreSQLã‹ã‚‰ç”¨èªè¾æ›¸ã‚’èª­ã¿è¾¼ã‚€"""
    if not PG_URL:
        return pd.DataFrame()
    
    try:
        engine = create_engine(PG_URL)
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ç¢ºèª
        with engine.connect() as conn:
            check_table = text("""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables 
                    WHERE table_schema = 'public' 
                    AND table_name = 'term_dictionary'
                );
            """)
            table_exists = conn.execute(check_table).scalar()
            
            if not table_exists:
                return pd.DataFrame()
        
        # ç”¨èªãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        if keyword:
            query = """
                SELECT term, synonyms, definition, sources, created_at
                FROM term_dictionary
                WHERE term ILIKE :keyword 
                   OR definition ILIKE :keyword
                   OR EXISTS (
                       SELECT 1 FROM unnest(synonyms) AS s 
                       WHERE s ILIKE :keyword
                   )
                ORDER BY term
            """
            params = {"keyword": f"%{keyword}%"}
        else:
            query = """
                SELECT term, synonyms, definition, sources, created_at
                FROM term_dictionary
                ORDER BY term
            """
            params = {}
        
        df = pd.read_sql(query, engine, params=params)
        
        if not df.empty and "created_at" in df.columns:
            df["created_at"] = pd.to_datetime(df["created_at"]).dt.strftime("%Y-%m-%d %H:%M")
        
        return df
        
    except Exception as e:
        st.error(f"ç”¨èªè¾æ›¸ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return pd.DataFrame()

def render_term_card(term_data: pd.Series):
    """ç”¨èªã‚«ãƒ¼ãƒ‰ã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°"""
    st.markdown(f"""
    <div class="term-card">
        <div class="term-headword">{term_data['term']}</div>
        <div class="term-definition">{term_data['definition']}</div>
        <div class="term-synonyms">
            <strong>é¡ç¾©èª:</strong> {', '.join(term_data['synonyms']) if term_data['synonyms'] else 'ãªã—'}
        </div>
        <div class="term-sources">
            <strong>å‡ºå…¸:</strong> {', '.join([Path(s).name for s in term_data['sources'][:3]]) if term_data['sources'] else 'ãªã—'}
            {f' ä»–{len(term_data["sources"])-3}ä»¶' if term_data['sources'] and len(term_data['sources']) > 3 else ''}
        </div>
    </div>
    """, unsafe_allow_html=True)

# â”€â”€ Initialize Session State â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "messages" not in st.session_state:
    st.session_state.messages = []
if "current_sources" not in st.session_state:
    st.session_state.current_sources = []
if "last_query_expansion" not in st.session_state:
    st.session_state.last_query_expansion = {}
if "use_query_expansion" not in st.session_state:
    st.session_state.use_query_expansion = False
if "use_rag_fusion" not in st.session_state:
    st.session_state.use_rag_fusion = False
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

if "rag_system" not in st.session_state:
    if ENV_DEFAULTS["AZURE_OPENAI_API_KEY"] and ENV_DEFAULTS["AZURE_OPENAI_ENDPOINT"] and \
       ENV_DEFAULTS["AZURE_OPENAI_CHAT_DEPLOYMENT_NAME"] and ENV_DEFAULTS["AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME"]:
        try:
            app_config = Config(
                azure_openai_api_key=ENV_DEFAULTS["AZURE_OPENAI_API_KEY"],
                azure_openai_endpoint=ENV_DEFAULTS["AZURE_OPENAI_ENDPOINT"],
                azure_openai_api_version=ENV_DEFAULTS["AZURE_OPENAI_API_VERSION"],
                azure_openai_chat_deployment_name=ENV_DEFAULTS["AZURE_OPENAI_CHAT_DEPLOYMENT_NAME"],
                azure_openai_embedding_deployment_name=ENV_DEFAULTS["AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME"],
                db_password=os.getenv("DB_PASSWORD", "postgres"),
                llm_model_identifier=ENV_DEFAULTS["LLM_MODEL_IDENTIFIER"],
                embedding_model_identifier=ENV_DEFAULTS["EMBEDDING_MODEL_IDENTIFIER"],
                collection_name=ENV_DEFAULTS["COLLECTION_NAME"],
                final_k=ENV_DEFAULTS["FINAL_K"]
            )
            st.session_state.rag_system = initialize_rag_system(app_config)
            st.toast("âœ… RAGã‚·ã‚¹ãƒ†ãƒ ãŒAzure OpenAIã§æ­£å¸¸ã«åˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ", icon="ğŸ‰")
        except Exception as e:
            st.error(f"Azure RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {type(e).__name__} - {e}")
            st.warning("""
### ğŸ”§ Azure OpenAI æ¥ç¶šã‚¨ãƒ©ãƒ¼ã®è§£æ±ºæ–¹æ³• (ä¸€èˆ¬çš„ãªä¾‹)

1.  **.envãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèªã—ã¦ãã ã•ã„**:
    `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT`, `AZURE_OPENAI_API_VERSION`,
    `AZURE_OPENAI_CHAT_DEPLOYMENT_NAME`, `AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME`
    ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚
2.  **ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå**: Azureãƒãƒ¼ã‚¿ãƒ«ã§è¨­å®šã—ãŸãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã¨åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåãŒæ­£ç¢ºã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚
3.  **ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¨APIãƒãƒ¼ã‚¸ãƒ§ãƒ³**: ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®URLã¨APIãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚
4.  **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶š**: Azure OpenAIã‚µãƒ¼ãƒ“ã‚¹ã¸ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼ˆãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«ã€ãƒ—ãƒ­ã‚­ã‚·è¨­å®šãªã©ï¼‰ã€‚
            """)
            st.session_state.rag_system = None
    else:
        st.warning("Azure OpenAIã®APIã‚­ãƒ¼ã¨é–¢é€£è¨­å®šãŒã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã‚’åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        st.session_state.rag_system = None

# â”€â”€ Main Header & Langsmith Info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""<div class="main-header"><h1 class="header-title">iRAG</h1><p class="header-subtitle">IHI's Smart Knowledge Base with SQL Analytics</p></div>""", unsafe_allow_html=True)

# LangSmith Tracing Info (Optional)
langsmith_api_key = os.getenv("LANGCHAIN_API_KEY")
langsmith_project = os.getenv("LANGCHAIN_PROJECT")
if langsmith_api_key:
    st.sidebar.success(f"Î¹Ï‡ LangSmith Tracing: ENABLED{' (Project: ' + langsmith_project + ')' if langsmith_project else ''}")
else:
    st.sidebar.info("Î¹Ï‡ LangSmith Tracing: DISABLED (ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„)")

rag: RAGSystem | None = st.session_state.get("rag_system")

# â”€â”€ Sidebar Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# --- Term Dictionary Extraction ---
with st.sidebar.expander("ğŸ“š ç”¨èªè¾æ›¸ç”Ÿæˆ", expanded=False):
    st.markdown("å°‚é–€ç”¨èªãƒ»é¡ç¾©èªè¾æ›¸ã‚’ PostgreSQL + pgvector ã«ä¿å­˜ã—ã¾ã™ã€‚")
    input_dir = st.text_input("å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€", value="./docs", key="term_input_dir")
    output_json = st.text_input("å‡ºåŠ› JSON ãƒ‘ã‚¹", value="./output/terms.json", key="term_output_json")
    if st.button("ğŸš€ æŠ½å‡ºå®Ÿè¡Œ", key="run_term_dict"):
        if rag is None:
            st.error("RAGã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        else:
            with st.spinner("ç”¨èªæŠ½å‡ºä¸­..."):
                try:
                    rag.extract_terms(input_dir, output_json)
                    st.success(f"è¾æ›¸ã‚’ç”Ÿæˆã—ã¾ã—ãŸ âœ”ï¸ â†’ {output_json}")
                except Exception as e:
                    st.error(f"ç”¨èªæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")

with st.sidebar:
    st.markdown("<h2 style='color: var(--text-primary);'>âš™ï¸ Configuration</h2>", unsafe_allow_html=True)
    if rag:
        service_type = "Azure OpenAI"
        st.success(f"âœ… System Online ({service_type}) - Collection: **{rag.config.collection_name}**")
    else:
        st.warning("âš ï¸ System Offline - Azure OpenAI APIã‚­ãƒ¼ã¾ãŸã¯DBè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    with st.form("config_form"):
        st.markdown("### ğŸ”‘ Azure OpenAI APIè¨­å®š")
        azure_api_key_input = st.text_input(
            "Azure OpenAI API Key",
            value=ENV_DEFAULTS["AZURE_OPENAI_API_KEY"] or "",
            type="password",
            help="Azure OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
        )
        azure_endpoint_input = st.text_input(
            "Azure OpenAI Endpoint",
            value=ENV_DEFAULTS["AZURE_OPENAI_ENDPOINT"] or "",
            help="Azure OpenAIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
        )
        azure_api_version_input = st.text_input(
            "Azure OpenAI API Version",
            value=ENV_DEFAULTS["AZURE_OPENAI_API_VERSION"] or "2024-02-01",
            help="Azure OpenAIã®APIãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (ä¾‹: 2024-02-01)ã€‚"
        )
        azure_chat_deployment_input = st.text_input(
            "Azure Chat Deployment Name",
            value=ENV_DEFAULTS["AZURE_OPENAI_CHAT_DEPLOYMENT_NAME"] or "",
            help="Azure OpenAIã®ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåã€‚"
        )
        azure_embedding_deployment_input = st.text_input(
            "Azure Embedding Deployment Name",
            value=ENV_DEFAULTS["AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME"] or "",
            help="Azure OpenAIã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåã€‚"
        )
        
        st.markdown("### ğŸ¤– Model Identifiers (UIç”¨)")
        embedding_model_options = ["text-embedding-ada-002", "text-embedding-3-small", "text-embedding-3-large"]
        llm_model_options = ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-4", "gpt-3.5-turbo"]

        current_emb_model_id = rag.config.embedding_model_identifier if rag and hasattr(rag.config, 'embedding_model_identifier') else ENV_DEFAULTS["EMBEDDING_MODEL_IDENTIFIER"]
        current_llm_model_id = rag.config.llm_model_identifier if rag and hasattr(rag.config, 'llm_model_identifier') else ENV_DEFAULTS["LLM_MODEL_IDENTIFIER"]
        current_collection_name = rag.config.collection_name if rag and hasattr(rag.config, 'collection_name') else ENV_DEFAULTS["COLLECTION_NAME"]
        current_final_k = rag.config.final_k if rag and hasattr(rag.config, 'final_k') else ENV_DEFAULTS["FINAL_K"]
        
        embedding_model_idx = embedding_model_options.index(current_emb_model_id) if current_emb_model_id in embedding_model_options else 0
        llm_model_idx = llm_model_options.index(current_llm_model_id) if current_llm_model_id in llm_model_options else 0

        embedding_model_id_sb = st.selectbox("Embedding Model Identifier", embedding_model_options, index=embedding_model_idx)
        llm_model_id_sb = st.selectbox("Language Model Identifier", llm_model_options, index=llm_model_idx)

        st.markdown("### ğŸ” Search Settings")
        collection_name_ti = st.text_input("Collection Name", value=current_collection_name)
        final_k_sl = st.slider("æ¤œç´¢çµæœæ•° (Final K)", 1, 20, current_final_k, help="LLMã«æ¸¡ã™æœ€çµ‚çš„ãªãƒãƒ£ãƒ³ã‚¯æ•°")

        apply_button = st.form_submit_button("Apply Settings", use_container_width=True)

if apply_button:
    base_config_params = {}
    if rag and hasattr(rag, 'config'):
        base_config_params = rag.config.__dict__.copy()
    else:
        try:
            base_config_params = Config().__dict__.copy()
        except Exception:
            pass

    updated_params_from_form = {
        "azure_openai_api_key": azure_api_key_input or base_config_params.get("azure_openai_api_key", ENV_DEFAULTS["AZURE_OPENAI_API_KEY"]),
        "azure_openai_endpoint": azure_endpoint_input or base_config_params.get("azure_openai_endpoint", ENV_DEFAULTS["AZURE_OPENAI_ENDPOINT"]),
        "azure_openai_api_version": azure_api_version_input or base_config_params.get("azure_openai_api_version", ENV_DEFAULTS["AZURE_OPENAI_API_VERSION"]),
        "azure_openai_chat_deployment_name": azure_chat_deployment_input or base_config_params.get("azure_openai_chat_deployment_name", ENV_DEFAULTS["AZURE_OPENAI_CHAT_DEPLOYMENT_NAME"]),
        "azure_openai_embedding_deployment_name": azure_embedding_deployment_input or base_config_params.get("azure_openai_embedding_deployment_name", ENV_DEFAULTS["AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME"]),
        "embedding_model_identifier": embedding_model_id_sb,
        "llm_model_identifier": llm_model_id_sb,
        "collection_name": collection_name_ti,
        "final_k": int(final_k_sl),
        "openai_api_key": None,
    }
    
    final_config_params = {**base_config_params, **updated_params_from_form}
    final_config_params["openai_api_key"] = None

    try:
        cfg_for_update = Config(**final_config_params)

        with st.spinner("è¨­å®šã‚’é©ç”¨ã—ã€ã‚·ã‚¹ãƒ†ãƒ ã‚’å†åˆæœŸåŒ–ã—ã¦ã„ã¾ã™..."):
            if "rag_system" in st.session_state:
                del st.session_state["rag_system"]
                st.cache_resource.clear()
            
            st.session_state.rag_system = initialize_rag_system(cfg_for_update)
            rag = st.session_state.rag_system
        st.success("âœ… è¨­å®šãŒæ­£å¸¸ã«é©ç”¨ã•ã‚Œã€ã‚·ã‚¹ãƒ†ãƒ ãŒå†åˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸã€‚")
        time.sleep(1)
        st.rerun()
    except Exception as e:
        st.error(f"è¨­å®šé©ç”¨ã‚¨ãƒ©ãƒ¼: {type(e).__name__} - {e}")

# â”€â”€ Main Tabsï¼ˆç”¨èªè¾æ›¸ã‚¿ãƒ–ã‚’è¿½åŠ ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
tab_titles = ["ğŸ’¬ Chat", "ğŸ“– Dictionary", "ğŸ—ƒï¸ Data", "ğŸ“ Documents", "âš™ï¸ Settings"]
tabs = st.tabs(tab_titles)
tab_chat, tab_dictionary, tab_data, tab_documents, tab_settings = tabs

# â”€â”€ Tab 1: Chat Interface (ChatGPT Style) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab_chat:
    if not rag:
        st.info("ğŸ”§ RAGã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Azure OpenAI APIã‚­ãƒ¼ã‚’è¨­å®šã—ã€ã€ŒApply Settingsã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã‹ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        has_messages = len(st.session_state.messages) > 0
        if not has_messages:
            st.markdown("""
            <div class="chat-welcome">
                <h2>Chat with your data</h2>
                <p style="color: var(--text-secondary);">
                    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰é–¢é€£æƒ…å ±ã‚’æ¤œç´¢ã—ã€AIãŒå›ç­”ã—ã¾ã™<br>
                    (Searches for relevant information from uploaded documents and AI answers)
                </p>
            </div>
            """, unsafe_allow_html=True)

            st.markdown('<div class="initial-input-container">', unsafe_allow_html=True)

            st.markdown("<h6>é«˜åº¦ãªRAGè¨­å®š:</h6>", unsafe_allow_html=True)
            opt_cols_initial = st.columns(2)
            with opt_cols_initial[0]:
                use_qe_initial = st.checkbox("ã‚¯ã‚¨ãƒªæ‹¡å¼µ", value=st.session_state.use_query_expansion, key="use_qe_initial_v7_tab_chat", help="è³ªå•ã‚’è‡ªå‹•çš„ã«æ‹¡å¼µã—ã¦æ¤œç´¢ (RRFãªã—)")
            with opt_cols_initial[1]:
                use_rf_initial = st.checkbox("RAG-Fusion", value=st.session_state.use_rag_fusion, key="use_rf_initial_v7_tab_chat", help="ã‚¯ã‚¨ãƒªæ‹¡å¼µã¨RRFã§çµæœã‚’çµ±åˆ")

            user_input_initial = st.text_area("è³ªå•ã‚’å…¥åŠ›:", placeholder="ä¾‹ï¼šã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è¦ç´„ã‚’æ•™ãˆã¦ãã ã•ã„ / å£²ä¸Šä¸Šä½10ä»¶ã‚’è¡¨ç¤ºã—ã¦", height=100, key="initial_input_textarea_v7_tab_chat", label_visibility="collapsed")

            if st.button("é€ä¿¡", type="primary", use_container_width=True, key="initial_send_button_v7_tab_chat"):
                if user_input_initial:
                    st.session_state.messages.append({"role": "user", "content": user_input_initial})
                    st.session_state.use_query_expansion = use_qe_initial
                    st.session_state.use_rag_fusion = use_rf_initial

                    with st.spinner("è€ƒãˆä¸­..."):
                        try:
                            trace_config = RunnableConfig(
                                run_name="RAG Initial Query Unified",
                                tags=["streamlit", "rag", "initial_query", st.session_state.session_id],
                                metadata={
                                    "session_id": st.session_state.session_id,
                                    "user_query": user_input_initial,
                                    "use_query_expansion": st.session_state.use_query_expansion,
                                    "use_rag_fusion": st.session_state.use_rag_fusion,
                                    "query_source": "initial_input"
                                }
                            )
                            if hasattr(rag, 'query_unified'):
                                response = rag.query_unified(
                                    user_input_initial,
                                    use_query_expansion=st.session_state.use_query_expansion,
                                    use_rag_fusion=st.session_state.use_rag_fusion,
                                    config=trace_config
                                )
                            else:
                                st.warning("è­¦å‘Š: `query_unified` ãƒ¡ã‚½ãƒƒãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ¨™æº–ã® `query` ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚SQLè‡ªå‹•åˆ¤åˆ¥ã¯æ©Ÿèƒ½ã—ã¾ã›ã‚“ã€‚")
                                response = rag.query(
                                    user_input_initial,
                                    use_query_expansion=st.session_state.use_query_expansion,
                                    use_rag_fusion=st.session_state.use_rag_fusion,
                                    config=trace_config
                                )

                            answer = response.get("answer", "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                            message_data: Dict[str, Any] = {"role": "assistant", "content": answer}

                            if response.get("query_type") == "sql" and response.get("sql_details"):
                                message_data["sql_details"] = response["sql_details"]
                            elif response.get("sql_details"):
                                message_data["sql_details"] = response["sql_details"]

                            st.session_state.messages.append(message_data)
                            st.session_state.current_sources = response.get("sources", [])
                            st.session_state.last_query_expansion = response.get("query_expansion", {})
                        except Exception as e:
                            st.error(f"ãƒãƒ£ãƒƒãƒˆå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {type(e).__name__} - {e}")
                    st.rerun()
            st.markdown('</div>', unsafe_allow_html=True)
        else:
            chat_col, source_col = st.columns([2, 1])
            with chat_col:
                message_container_height = 600
                with st.container(height=message_container_height):
                    for idx, message in enumerate(st.session_state.messages):
                        avatar_char = "ğŸ‘¤" if message['role'] == 'user' else "ğŸ¤–"
                        avatar_class = 'user-avatar' if message['role'] == 'user' else 'ai-avatar'
                        avatar_html = f"<div class='avatar {avatar_class}'>{avatar_char}</div>"
                        
                        st.markdown(f"<div class='message-row {'user-message-row' if message['role'] == 'user' else 'ai-message-row'}'>{avatar_html}<div class='message-content'>{message['content']}</div></div>", unsafe_allow_html=True)

                        if message['role'] == 'assistant' and message.get("sql_details"):
                            render_sql_result_in_chat(message["sql_details"])

                st.markdown("---")

                opt_cols_chat = st.columns(2)
                with opt_cols_chat[0]:
                    use_qe_chat = st.checkbox("ã‚¯ã‚¨ãƒªæ‹¡å¼µ", value=st.session_state.use_query_expansion, key="use_qe_chat_continued_v7_tab_chat", help="ã‚¯ã‚¨ãƒªæ‹¡å¼µ (RRFãªã—)")
                with opt_cols_chat[1]:
                    use_rf_chat = st.checkbox("RAG-Fusion", value=st.session_state.use_rag_fusion, key="use_rf_chat_continued_v7_tab_chat", help="RAG-Fusion (æ‹¡å¼µ+RRF)")

                user_input_continued = st.text_area(
                    "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›:",
                    placeholder="ç¶šã‘ã¦è³ªå•ã—ã¦ãã ã•ã„...",
                    label_visibility="collapsed",
                    key=f"chat_input_continued_text_v7_tab_chat_{len(st.session_state.messages)}"
                )

                if st.button("é€ä¿¡", type="primary", key=f"chat_send_button_continued_v7_tab_chat_{len(st.session_state.messages)}", use_container_width=True):
                    if user_input_continued:
                        st.session_state.messages.append({"role": "user", "content": user_input_continued})
                        st.session_state.use_query_expansion = use_qe_chat
                        st.session_state.use_rag_fusion = use_rf_chat
                        with st.spinner("è€ƒãˆä¸­..."):
                            try:
                                trace_config_cont = RunnableConfig(
                                    run_name="RAG Chat Query Unified",
                                    tags=["streamlit", "rag", "chat_query", st.session_state.session_id],
                                    metadata={
                                        "session_id": st.session_state.session_id,
                                        "user_query": user_input_continued,
                                        "use_query_expansion": st.session_state.use_query_expansion,
                                        "use_rag_fusion": st.session_state.use_rag_fusion,
                                        "query_source": "continued_chat"
                                    }
                                )
                                if hasattr(rag, 'query_unified'):
                                    response = rag.query_unified(
                                        user_input_continued,
                                        use_query_expansion=st.session_state.use_query_expansion,
                                        use_rag_fusion=st.session_state.use_rag_fusion,
                                        config=trace_config_cont
                                    )
                                else:
                                    st.warning("è­¦å‘Š: `query_unified` ãƒ¡ã‚½ãƒƒãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ¨™æº–ã® `query` ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚SQLè‡ªå‹•åˆ¤åˆ¥ã¯æ©Ÿèƒ½ã—ã¾ã›ã‚“ã€‚")
                                    response = rag.query(
                                        user_input_continued,
                                        use_query_expansion=st.session_state.use_query_expansion,
                                        use_rag_fusion=st.session_state.use_rag_fusion,
                                        config=trace_config_cont
                                    )

                                answer = response.get("answer", "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                                message_data_cont: Dict[str, Any] = {"role": "assistant", "content": answer}

                                if response.get("query_type") == "sql" and response.get("sql_details"):
                                    message_data_cont["sql_details"] = response["sql_details"]
                                elif response.get("sql_details"):
                                    message_data_cont["sql_details"] = response["sql_details"]

                                st.session_state.messages.append(message_data_cont)
                                st.session_state.current_sources = response.get("sources", [])
                                st.session_state.last_query_expansion = response.get("query_expansion", {})
                            except Exception as e:
                                st.error(f"ãƒãƒ£ãƒƒãƒˆå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {type(e).__name__} - {e}")
                        st.rerun()

                button_col, info_col = st.columns([1, 3])
                with button_col:
                    if st.button("ğŸ—‘ï¸ ä¼šè©±ã‚’ã‚¯ãƒªã‚¢", use_container_width=True, key="clear_chat_button_v7_tab_chat"):
                        st.session_state.messages = []
                        st.session_state.current_sources = []
                        st.session_state.last_query_expansion = {}
                        st.rerun()
                with info_col:
                    last_expansion = st.session_state.get("last_query_expansion", {})
                    if last_expansion and last_expansion.get("used", False):
                        with st.expander(f"ğŸ“‹ æ‹¡å¼µã‚¯ã‚¨ãƒªè©³ç´° ({last_expansion.get('strategy', 'N/A')})", expanded=False):
                            queries = last_expansion.get("queries", [])
                            st.caption("ä»¥ä¸‹ã®ã‚¯ã‚¨ãƒªã§æ¤œç´¢ã—ã¾ã—ãŸï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰ï¼š")
                            for i, q_text in enumerate(queries):
                                st.write(f"â€¢ {'**' if i == 0 else ''}{q_text}{'** (å…ƒã®è³ªå•)' if i == 0 else ''}")
                    elif any(msg.get("sql_details") for msg in st.session_state.messages if msg["role"] == "assistant"):
                        st.caption("SQLåˆ†æãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸã€‚è©³ç´°ã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…ã®å®Ÿè¡Œçµæœã‚’ã”ç¢ºèªãã ã•ã„ã€‚")

            with source_col:
                st.markdown("""<div style="position: sticky; top: 1rem;"><h4 style="color: var(--text-primary); margin-bottom: 1rem;">ğŸ“š å‚ç…§ã‚½ãƒ¼ã‚¹ (RAG)</h4></div>""", unsafe_allow_html=True)
                if st.session_state.current_sources:
                    for i, source in enumerate(st.session_state.current_sources):
                        doc_id = source.get('metadata', {}).get('document_id', 'Unknown Document')
                        chunk_id_val = source.get('metadata', {}).get('chunk_id', f'N/A_{i}')
                        excerpt = source.get('excerpt', 'æŠœç²‹ãªã—')
                        
                        expander_key = f"source_expander_chat_{st.session_state.session_id}_{chunk_id_val}_tab_chat"
                        
                        with st.expander(f"ã‚½ãƒ¼ã‚¹ {i+1}: {doc_id} (Chunk: {chunk_id_val})", expanded=False):
                            st.markdown(f"""<div class="source-excerpt" style="margin-bottom: 1rem;">{excerpt}</div>""", unsafe_allow_html=True)
                            
                            button_key = f"full_text_btn_chat_{st.session_state.session_id}_{chunk_id_val}_tab_chat"
                            show_full_text_key = f"show_full_chat_{st.session_state.session_id}_{chunk_id_val}_tab_chat"

                            if st.button(f"å…¨æ–‡ã‚’è¡¨ç¤º##{chunk_id_val}", key=button_key):
                                st.session_state[show_full_text_key] = not st.session_state.get(show_full_text_key, False)
                            
                            if st.session_state.get(show_full_text_key, False):
                                full_text = source.get('full_content', 'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãªã—')
                                st.markdown(f"""<div class="full-text-container">{full_text}</div>""", unsafe_allow_html=True)
                else:
                    st.info("RAGæ¤œç´¢ãŒå®Ÿè¡Œã•ã‚Œã‚‹ã¨ã€å‚ç…§ã—ãŸã‚½ãƒ¼ã‚¹ãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

# â”€â”€ Tab 2: Dictionary (ç”¨èªè¾æ›¸) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab_dictionary:
    st.markdown("### ğŸ“– å°‚é–€ç”¨èªè¾æ›¸")
    st.caption("ç™»éŒ²ã•ã‚ŒãŸå°‚é–€ç”¨èªãƒ»é¡ç¾©èªã‚’æ¤œç´¢ãƒ»ç¢ºèªã§ãã¾ã™ã€‚")
    
    if not PG_URL:
        st.warning("âš ï¸ PG_URLãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ç”¨èªè¾æ›¸æ©Ÿèƒ½ã‚’åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã§PG_URLã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    else:
        # æ¤œç´¢ãƒœãƒƒã‚¯ã‚¹
        col1, col2 = st.columns([3, 1])
        with col1:
            search_keyword = st.text_input(
                "ğŸ” ç”¨èªæ¤œç´¢",
                placeholder="æ¤œç´¢ã—ãŸã„ç”¨èªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...",
                key="term_search_input"
            )
        with col2:
            st.markdown("<br>", unsafe_allow_html=True)  # ã‚¹ãƒšãƒ¼ã‚µãƒ¼
            if st.button("ğŸ”„ æ›´æ–°", key="refresh_terms", use_container_width=True):
                st.cache_data.clear()
                st.rerun()
        
        # ç”¨èªãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        with st.spinner("ç”¨èªè¾æ›¸ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
            terms_df = load_terms_from_db(search_keyword)
        
        if terms_df.empty:
            if search_keyword:
                st.info(f"ã€Œ{search_keyword}ã€ã«è©²å½“ã™ã‚‹ç”¨èªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                st.info("ã¾ã ç”¨èªãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€ŒğŸ“š ç”¨èªè¾æ›¸ç”Ÿæˆã€ã‹ã‚‰ç”¨èªã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚")
        else:
            # çµ±è¨ˆæƒ…å ±
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ç™»éŒ²ç”¨èªæ•°", f"{len(terms_df):,}")
            with col2:
                total_synonyms = sum(len(syn_list) if syn_list else 0 for syn_list in terms_df['synonyms'])
                st.metric("é¡ç¾©èªç·æ•°", f"{total_synonyms:,}")
            with col3:
                unique_sources = set()
                for sources in terms_df['sources']:
                    if sources:
                        unique_sources.update(sources)
                st.metric("å‚ç…§æ–‡æ›¸æ•°", f"{len(unique_sources):,}")
            
            st.markdown("---")
            
            # è¡¨ç¤ºå½¢å¼ã®é¸æŠ
            view_mode = st.radio(
                "è¡¨ç¤ºå½¢å¼",
                ["ã‚«ãƒ¼ãƒ‰å½¢å¼", "ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼"],
                horizontal=True,
                key="dict_view_mode"
            )
            
            if view_mode == "ã‚«ãƒ¼ãƒ‰å½¢å¼":
                # ã‚«ãƒ¼ãƒ‰å½¢å¼ã§ã®è¡¨ç¤º
                for idx, row in terms_df.iterrows():
                    render_term_card(row)
            else:
                # ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§ã®è¡¨ç¤º
                display_df = terms_df.copy()
                # é…åˆ—ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
                display_df['synonyms'] = display_df['synonyms'].apply(
                    lambda x: ', '.join(x) if x else ''
                )
                display_df['sources'] = display_df['sources'].apply(
                    lambda x: ', '.join([Path(s).name for s in x[:2]]) + f' ä»–{len(x)-2}ä»¶' if x and len(x) > 2 else ', '.join([Path(s).name for s in x]) if x else ''
                )
                
                # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«
                display_df.columns = ['ç”¨èª', 'é¡ç¾©èª', 'å®šç¾©', 'å‡ºå…¸', 'ç™»éŒ²æ—¥æ™‚']
                
                st.dataframe(
                    display_df,
                    use_container_width=True,
                    hide_index=True,
                    height=min(600, (len(display_df) + 1) * 35 + 3)
                )
            
            # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            st.markdown("---")
            if st.button("ğŸ“¥ ç”¨èªè¾æ›¸ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key="download_terms_csv"):
                csv = terms_df.to_csv(index=False)
                st.download_button(
                    label="ğŸ’¾ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv,
                    file_name=f"term_dictionary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    key="csv_download_button"
                )

# â”€â”€ Tab 3: Data Management (SQLç”¨ãƒ†ãƒ¼ãƒ–ãƒ«) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab_data:
    if not rag:
        st.info("RAGã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    elif not all(hasattr(rag, attr) for attr in ['create_table_from_file', 'get_data_tables', 'delete_data_table']):
        st.warning("RAGã‚·ã‚¹ãƒ†ãƒ ãŒãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ç®¡ç†æ©Ÿèƒ½ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ã€‚")
    else:
        st.markdown("### ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç† (SQLåˆ†æç”¨)")
        st.caption("Excel/CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€SQLã§åˆ†æå¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆãƒ»ç®¡ç†ã—ã¾ã™ã€‚")

        uploaded_sql_data_files_list = st.file_uploader(
            "Excel/CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ (.xlsx, .xls, .csv)",
            accept_multiple_files=True,
            type=["xlsx", "xls", "csv"],
            key="sql_data_file_uploader_v7_tab_data"
        )

        if uploaded_sql_data_files_list:
            if st.button("ğŸš€ é¸æŠã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ/æ›´æ–°", type="primary", key="create_table_button_v7_tab_data"):
                progress_bar_sql_data_create = st.progress(0, text="å‡¦ç†é–‹å§‹...")
                status_text_sql_data_create = st.empty()

                for i, file_item_sql in enumerate(uploaded_sql_data_files_list):
                    status_text_sql_data_create.info(f"å‡¦ç†ä¸­: {file_item_sql.name}")
                    try:
                        temp_dir_for_sql_data_path = Path(tempfile.gettempdir()) / "rag_sql_data_uploads"
                        temp_dir_for_sql_data_path.mkdir(parents=True, exist_ok=True)
                        temp_file_path_sql = temp_dir_for_sql_data_path / file_item_sql.name
                        with open(temp_file_path_sql, "wb") as f:
                            f.write(file_item_sql.getbuffer())

                        success_create, message_create, schema_info_create = rag.create_table_from_file(str(temp_file_path_sql))
                        if success_create:
                            st.success(f"âœ… {file_item_sql.name}: {message_create}")
                            if schema_info_create:
                                st.text("ä½œæˆ/æ›´æ–°ã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒ:")
                                st.code(schema_info_create, language='text')
                        else:
                            st.error(f"âŒ {file_item_sql.name}: {message_create}")
                    except Exception as e_upload_sql:
                        st.error(f"âŒ {file_item_sql.name} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {type(e_upload_sql).__name__} - {e_upload_sql}")
                    finally:
                        progress_bar_sql_data_create.progress((i + 1) / len(uploaded_sql_data_files_list), text=f"å®Œäº†: {file_item_sql.name}")

                if 'progress_bar_sql_data_create' in locals(): progress_bar_sql_data_create.empty()
                if 'status_text_sql_data_create' in locals(): status_text_sql_data_create.empty()
                st.rerun()

        st.markdown("---")
        st.markdown("### ğŸ“‹ ç™»éŒ²æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«")
        tables_list_display = rag.get_data_tables()
        if tables_list_display:
            for table_info_item in tables_list_display:
                table_name_display = table_info_item.get('table_name', 'ä¸æ˜ãªãƒ†ãƒ¼ãƒ–ãƒ«')
                row_count_display = table_info_item.get('row_count', 'N/A')
                schema_display_text = table_info_item.get('schema', 'ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ãªã—')
                with st.expander(f"ğŸ“Š {table_name_display} ({row_count_display:,}è¡Œ)"):
                    st.code(schema_display_text, language='text')
                    st.warning(f"**æ³¨æ„:** ãƒ†ãƒ¼ãƒ–ãƒ« '{table_name_display}' ã‚’å‰Šé™¤ã™ã‚‹ã¨å…ƒã«æˆ»ã›ã¾ã›ã‚“ã€‚")
                    if st.button(f"ğŸ—‘ï¸ ãƒ†ãƒ¼ãƒ–ãƒ« '{table_name_display}' ã‚’å‰Šé™¤", key=f"delete_table_{table_name_display}_v7_tab_data", type="secondary"):
                        with st.spinner(f"ãƒ†ãƒ¼ãƒ–ãƒ« '{table_name_display}' ã‚’å‰Šé™¤ä¸­..."):
                            del_success_flag, del_msg_text = rag.delete_data_table(table_name_display)
                        if del_success_flag:
                            st.success(del_msg_text)
                            st.rerun()
                        else:
                            st.error(del_msg_text)
        else:
            st.info("åˆ†æå¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚ä¸Šè¨˜ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")